{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1e25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from folder: Cataract_median_equalized\n",
      "Reading images from folder: Diabetic Retinopathy_equalized\n",
      "Reading images from folder: Normal_median_equalized\n",
      "Reading images from folder: Glaucoma_median_equalized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the base directory where your folders are stored\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Ocular Dataset\"\n",
    "\n",
    "# List of folder names to read images from\n",
    "folders = [\"Cataract_median_equalized\", \"Diabetic Retinopathy_equalized\", \"Normal_median_equalized\", \"Glaucoma_median_equalized\"]\n",
    "\n",
    "# Dictionary to store images from each folder\n",
    "images_by_folder = {}\n",
    "\n",
    "# Function to read images from a specified folder and store in the dictionary\n",
    "def read_images(folder_name):\n",
    "    # Path to the specific folder\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "\n",
    "    # Get all image file names in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # List to store images from this folder\n",
    "    images = []\n",
    "\n",
    "    # Read and store each image in the list\n",
    "    for image_file in image_files:\n",
    "        # Read the image in color\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "        else:\n",
    "            print(f\"Could not read the image: {image_file}\")\n",
    "\n",
    "    # Store the list of images in the dictionary with the folder name as the key\n",
    "    images_by_folder[folder_name] = images\n",
    "\n",
    "# Loop through each folder and read the images\n",
    "for folder in folders:\n",
    "    print(f\"Reading images from folder: {folder}\")\n",
    "    read_images(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1206d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3032c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: Cataract_median_equalized\n",
      "Extracted HOG features from 1032 images in 'Cataract_median_equalized'\n",
      "Processing subfolder: Diabetic Retinopathy_equalized\n",
      "Extracted HOG features from 1098 images in 'Diabetic Retinopathy_equalized'\n",
      "Processing subfolder: Normal_median_equalized\n",
      "Extracted HOG features from 1074 images in 'Normal_median_equalized'\n",
      "Processing subfolder: Glaucoma_median_equalized\n",
      "Extracted HOG features from 1007 images in 'Glaucoma_median_equalized'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Base directory where subfolders are located\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Ocular Dataset\"\n",
    "\n",
    "# List of specific subfolders to process\n",
    "specific_subfolders = [\"Cataract_median_equalized\", \"Diabetic Retinopathy_equalized\", \"Normal_median_equalized\", \"Glaucoma_median_equalized\"]\n",
    "\n",
    "# Filter subfolders to process only specific ones\n",
    "subfolders = [f for f in specific_subfolders if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "# Dictionary to store features for specific subfolders\n",
    "features_by_folder = {}\n",
    "\n",
    "# Function to extract HOG features from a grayscale image\n",
    "def extract_hog_features(image):\n",
    "    # Extract HOG features and a visualization image\n",
    "    hog_features, hog_image = hog(image, visualize=True, pixels_per_cell=(16, 16), cells_per_block=(1, 1), feature_vector=True)\n",
    "    \n",
    "    # Rescale the HOG image for visualization (optional)\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    \n",
    "    return hog_features, hog_image_rescaled\n",
    "\n",
    "# Function to read images from a folder and extract HOG features\n",
    "def read_and_extract_features(folder_path):\n",
    "    # List all image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Store HOG features from this folder\n",
    "    hog_features_list = []\n",
    "\n",
    "    # Loop through each image and extract HOG features\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is not None:\n",
    "            # Extract HOG features\n",
    "            hog_features, _ = extract_hog_features(image)\n",
    "\n",
    "            # Append the HOG features to the list\n",
    "            hog_features_list.append(hog_features)\n",
    "    \n",
    "    return hog_features_list\n",
    "\n",
    "# Loop through each subfolder to extract HOG features\n",
    "for subfolder in subfolders:\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "    folder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    # Extract features from the current subfolder\n",
    "    features = read_and_extract_features(folder_path)\n",
    "\n",
    "    # Store the extracted features in the dictionary\n",
    "    features_by_folder[subfolder] = features\n",
    "\n",
    "    # Provide feedback on the number of images processed\n",
    "    print(f\"Extracted HOG features from {len(features)} images in '{subfolder}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing segmentation for subfolder: Cataract_median_equalized\n",
      "Segmented 1032 images in 'Cataract_median_equalized'\n",
      "Processing segmentation for subfolder: Diabetic Retinopathy_equalized\n",
      "Segmented 1098 images in 'Diabetic Retinopathy_equalized'\n",
      "Processing segmentation for subfolder: Normal_median_equalized\n",
      "Segmented 1074 images in 'Normal_median_equalized'\n",
      "Processing segmentation for subfolder: Glaucoma_median_equalized\n",
      "Segmented 1007 images in 'Glaucoma_median_equalized'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Base directory where subfolders are located\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Ocular Dataset\"\n",
    "\n",
    "# List of specific subfolders to process\n",
    "specific_subfolders = [\"Cataract_median_equalized\", \"Diabetic Retinopathy_equalized\", \"Normal_median_equalized\", \"Glaucoma_median_equalized\"]\n",
    "# Dictionary to store segmented images for each subfolder\n",
    "segmented_by_folder = {}\n",
    "\n",
    "# Function to apply Otsu's Thresholding for segmentation\n",
    "def otsu_threshold_segmentation(image):\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply Otsu's Thresholding to segment the image\n",
    "    _, segmented_image = cv2.threshold(\n",
    "        blurred_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "# Function to read images from a folder and apply segmentation\n",
    "def read_and_segment_images(folder_path):\n",
    "    # List all image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # List to store segmented images\n",
    "    segmented_images = []\n",
    "\n",
    "    # Loop through each image and apply segmentation\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is not None:\n",
    "            # Apply Otsu's Thresholding for segmentation\n",
    "            segmented_image = otsu_threshold_segmentation(image)\n",
    "\n",
    "            # Store the segmented image in the list\n",
    "            segmented_images.append({\n",
    "                'original_image': image,\n",
    "                'segmented_image': segmented_image,\n",
    "            })\n",
    "\n",
    "    return segmented_images\n",
    "\n",
    "# Loop through each specified subfolder to extract and store segmented images\n",
    "for subfolder in specific_subfolders:\n",
    "    print(f\"Processing segmentation for subfolder: {subfolder}\")\n",
    "    folder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    # Apply segmentation and store in memory\n",
    "    segmented_images = read_and_segment_images(folder_path)\n",
    "\n",
    "    # Store the segmented images in a dictionary\n",
    "    segmented_by_folder[subfolder] = segmented_images\n",
    "\n",
    "    # Provide feedback on the number of segmented images\n",
    "    print(f\"Segmented {len(segmented_images)} images in '{subfolder}'\")\n",
    "\n",
    "# Now `segmented_by_folder` contains all segmented images in memory, which can be used for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a27dff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af466c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3371 images belonging to 4 classes.\n",
      "Found 840 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 83s 765ms/step - loss: 1.0176 - accuracy: 0.5268 - val_loss: 0.8416 - val_accuracy: 0.5690\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 60s 564ms/step - loss: 0.7081 - accuracy: 0.6811 - val_loss: 0.7414 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 60s 567ms/step - loss: 0.5995 - accuracy: 0.7404 - val_loss: 0.5826 - val_accuracy: 0.7345\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 60s 566ms/step - loss: 0.5167 - accuracy: 0.7820 - val_loss: 0.5938 - val_accuracy: 0.7274\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 60s 566ms/step - loss: 0.4641 - accuracy: 0.8015 - val_loss: 0.5791 - val_accuracy: 0.7429\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 60s 564ms/step - loss: 0.4123 - accuracy: 0.8300 - val_loss: 0.6366 - val_accuracy: 0.7298\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 60s 569ms/step - loss: 0.3869 - accuracy: 0.8413 - val_loss: 0.6833 - val_accuracy: 0.6905\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 60s 567ms/step - loss: 0.3436 - accuracy: 0.8600 - val_loss: 0.6452 - val_accuracy: 0.7262\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 61s 572ms/step - loss: 0.2949 - accuracy: 0.8793 - val_loss: 0.7257 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 61s 572ms/step - loss: 0.2493 - accuracy: 0.8985 - val_loss: 0.7379 - val_accuracy: 0.7310\n",
      "27/27 [==============================] - 4s 139ms/step - loss: 0.7379 - accuracy: 0.7310\n",
      "Validation accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil  # This will help to copy files and folders\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Base directory for the dataset\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Ocular Dataset\"\n",
    "\n",
    "# List of specific subfolders to process\n",
    "target_subfolders = [\"Cataract_median_equalized\", \"Diabetic Retinopathy_equalized\", \"Normal_median_equalized\", \"Glaucoma_median_equalized\"]\n",
    "\n",
    "# Create a new temporary base directory\n",
    "temp_base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Temp\"\n",
    "\n",
    "# Ensure the temporary base directory is empty and exists\n",
    "if os.path.exists(temp_base_dir):\n",
    "    shutil.rmtree(temp_base_dir)  # Clear if exists\n",
    "os.makedirs(temp_base_dir, exist_ok=True)  # Create a fresh folder\n",
    "\n",
    "# Copy the specified subfolders to the temporary base directory\n",
    "for subfolder in target_subfolders:\n",
    "    src_path = os.path.join(base_dir, subfolder)\n",
    "    dest_path = os.path.join(temp_base_dir, subfolder)\n",
    "\n",
    "    # Copy the entire subfolder if it exists\n",
    "    if os.path.isdir(src_path):\n",
    "        shutil.copytree(src_path, dest_path)\n",
    "\n",
    "# Prepare the data generator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Training dataset from specified subfolders\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation dataset from specified subfolders\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define a simple CNN model\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer for categorical classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da67499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3371 images belonging to 4 classes.\n",
      "Found 840 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 308s 3s/step - loss: 1.3543 - accuracy: 0.3664 - val_loss: 1.1533 - val_accuracy: 0.4071\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 309s 3s/step - loss: 0.9679 - accuracy: 0.5188 - val_loss: 0.8740 - val_accuracy: 0.5274\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 314s 3s/step - loss: 0.8247 - accuracy: 0.5731 - val_loss: 0.8421 - val_accuracy: 0.5512\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 303s 3s/step - loss: 0.7989 - accuracy: 0.5957 - val_loss: 0.8255 - val_accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 301s 3s/step - loss: 0.6749 - accuracy: 0.6719 - val_loss: 0.7922 - val_accuracy: 0.6048\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 348s 3s/step - loss: 0.6542 - accuracy: 0.6968 - val_loss: 0.9217 - val_accuracy: 0.5631\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 343s 3s/step - loss: 0.6053 - accuracy: 0.7155 - val_loss: 0.9679 - val_accuracy: 0.5452\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 356s 3s/step - loss: 0.5298 - accuracy: 0.7609 - val_loss: 0.8114 - val_accuracy: 0.6048\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 368s 3s/step - loss: 0.5195 - accuracy: 0.7668 - val_loss: 1.3849 - val_accuracy: 0.5607\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 358s 3s/step - loss: 0.5003 - accuracy: 0.7737 - val_loss: 1.1999 - val_accuracy: 0.5726\n",
      "27/27 [==============================] - 20s 749ms/step - loss: 1.1999 - accuracy: 0.5726\n",
      "Validation accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Temporary base directory for the dataset\n",
    "temp_base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Temp\"\n",
    "\n",
    "# Prepare the data generator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Training dataset from specified subfolders\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(227, 227),  # AlexNet uses 227x227 images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation dataset from specified subfolders\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define an AlexNet architecture\n",
    "alexnet_model = models.Sequential([\n",
    "    layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(227, 227, 3)),  # Conv1\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),  # Pool1\n",
    "    layers.Conv2D(256, (5, 5), padding='same', activation='relu'),  # Conv2\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),  # Pool2\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),  # Conv3\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),  # Conv4\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),  # Conv5\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),  # Pool3\n",
    "    layers.Flatten(),  # Flattening for fully connected layers\n",
    "    layers.Dense(4096, activation='relu'),  # FC6\n",
    "    layers.Dropout(0.5),  # Dropout for regularization\n",
    "    layers.Dense(4096, activation='relu'),  # FC7\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer for categorical classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "alexnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = alexnet_model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493fe59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3371 images belonging to 4 classes.\n",
      "Found 840 images belonging to 4 classes.\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 425s 4s/step - loss: 1.0506 - accuracy: 0.5013 - val_loss: 0.8968 - val_accuracy: 0.5155\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 393s 4s/step - loss: 0.7459 - accuracy: 0.6253 - val_loss: 0.9203 - val_accuracy: 0.5274\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 523s 5s/step - loss: 0.6010 - accuracy: 0.7048 - val_loss: 1.3219 - val_accuracy: 0.5393\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 650s 6s/step - loss: 0.5530 - accuracy: 0.7419 - val_loss: 0.9299 - val_accuracy: 0.5393\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 948s 9s/step - loss: 0.5102 - accuracy: 0.7656 - val_loss: 1.0165 - val_accuracy: 0.5548\n",
      "27/27 [==============================] - 60s 2s/step - loss: 1.0165 - accuracy: 0.5548\n",
      "Validation accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Temporary base directory for the dataset\n",
    "temp_base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Temp\"\n",
    "\n",
    "# Data generator with data augmentation and validation split\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Training dataset from specified subfolders\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(224, 224),  # VGG-like networks use 224x224 images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation dataset from specified subfolders\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    temp_base_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define a simplified VGG-like architecture\n",
    "simple_vgg = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output for categorical classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "simple_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "simple_vgg.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = simple_vgg.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63cfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
