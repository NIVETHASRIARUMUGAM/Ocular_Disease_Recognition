{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8009f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: Cataract/Cataract_low\n",
      "Extracted HOG features from 382 images in 'Cataract/Cataract_low'\n",
      "Processing subfolder: Cataract/Cataract_medium\n",
      "Extracted HOG features from 350 images in 'Cataract/Cataract_medium'\n",
      "Processing subfolder: Cataract/Cataract_high\n",
      "Extracted HOG features from 300 images in 'Cataract/Cataract_high'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_low\n",
      "Extracted HOG features from 317 images in 'Diabetic Retinopathy/Diabetic Retinopathy_low'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_medium\n",
      "Extracted HOG features from 401 images in 'Diabetic Retinopathy/Diabetic Retinopathy_medium'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_high\n",
      "Extracted HOG features from 380 images in 'Diabetic Retinopathy/Diabetic Retinopathy_high'\n",
      "Processing main folder: Normal\n",
      "Extracted HOG features from 1074 images in 'Normal'\n",
      "Processing subfolder: Glaucoma/Glaucoma_low\n",
      "Extracted HOG features from 354 images in 'Glaucoma/Glaucoma_low'\n",
      "Processing subfolder: Glaucoma/Glaucoma_medium\n",
      "Extracted HOG features from 298 images in 'Glaucoma/Glaucoma_medium'\n",
      "Processing subfolder: Glaucoma/Glaucoma_high\n",
      "Extracted HOG features from 355 images in 'Glaucoma/Glaucoma_high'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Base directory where the main folders are located\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Severities\"\n",
    "\n",
    "# Main folders with their subfolders\n",
    "main_folders = {\n",
    "    \"Cataract\": [\"Cataract_low\", \"Cataract_medium\", \"Cataract_high\"],\n",
    "    \"Diabetic Retinopathy\": [\"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\"],\n",
    "    \"Normal\": [],  # No subfolders for Normal\n",
    "    \"Glaucoma\": [\"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"],\n",
    "}\n",
    "\n",
    "# Dictionary to store features for all subfolders\n",
    "features_by_folder = {}\n",
    "\n",
    "# Function to extract HOG features from a grayscale image\n",
    "def extract_hog_features(image):\n",
    "    # Extract HOG features and a visualization image\n",
    "    hog_features, hog_image = hog(image, visualize=True, pixels_per_cell=(16, 16), cells_per_block=(1, 1), feature_vector=True)\n",
    "    \n",
    "    # Rescale the HOG image for visualization (optional)\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    \n",
    "    return hog_features, hog_image_rescaled\n",
    "\n",
    "# Function to read images from a folder and extract HOG features\n",
    "def read_and_extract_features(folder_path):\n",
    "    # List all image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Store HOG features from this folder\n",
    "    hog_features_list = []\n",
    "\n",
    "    # Loop through each image and extract HOG features\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is not None:\n",
    "            # Extract HOG features\n",
    "            hog_features, _ = extract_hog_features(image)\n",
    "\n",
    "            # Append the HOG features to the list\n",
    "            hog_features_list.append(hog_features)\n",
    "    \n",
    "    return hog_features_list\n",
    "\n",
    "# Loop through each main folder and its subfolders to extract HOG features\n",
    "for main_folder, subfolder_list in main_folders.items():\n",
    "    if subfolder_list:\n",
    "        # Process each subfolder under the main folder\n",
    "        for subfolder in subfolder_list:\n",
    "            print(f\"Processing subfolder: {main_folder}/{subfolder}\")\n",
    "            folder_path = os.path.join(base_dir, main_folder, subfolder)\n",
    "\n",
    "            # Extract features from the current subfolder\n",
    "            features = read_and_extract_features(folder_path)\n",
    "\n",
    "            # Store the extracted features in the dictionary\n",
    "            features_by_folder[f\"{main_folder}/{subfolder}\"] = features\n",
    "\n",
    "            # Provide feedback on the number of images processed\n",
    "            print(f\"Extracted HOG features from {len(features)} images in '{main_folder}/{subfolder}'\")\n",
    "    else:\n",
    "        # If no subfolders, process the main folder directly (like Normal)\n",
    "        print(f\"Processing main folder: {main_folder}\")\n",
    "        folder_path = os.path.join(base_dir, main_folder)\n",
    "\n",
    "        # Extract features from the current main folder\n",
    "        features = read_and_extract_features(folder_path)\n",
    "\n",
    "        # Store the extracted features in the dictionary\n",
    "        features_by_folder[main_folder] = features\n",
    "\n",
    "        # Provide feedback on the number of images processed\n",
    "        print(f\"Extracted HOG features from {len(features)} images in '{main_folder}'\")\n",
    "\n",
    "# Now 'features_by_folder' contains HOG features from all specified folders and subfolders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58021c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3371 images belonging to 4 classes.\n",
      "Found 840 images belonging to 4 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 16s 1us/step\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1896s 18s/step - loss: 0.8669 - accuracy: 0.6446 - val_loss: 0.6183 - val_accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 2396s 23s/step - loss: 0.6367 - accuracy: 0.7321 - val_loss: 0.4743 - val_accuracy: 0.8274\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 2439s 23s/step - loss: 0.5755 - accuracy: 0.7603 - val_loss: 0.4748 - val_accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 2165s 20s/step - loss: 0.5563 - accuracy: 0.7787 - val_loss: 0.3927 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 2073s 20s/step - loss: 0.5237 - accuracy: 0.7903 - val_loss: 0.4052 - val_accuracy: 0.8607\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 2420s 23s/step - loss: 0.5173 - accuracy: 0.7909 - val_loss: 0.4456 - val_accuracy: 0.8321\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1588s 15s/step - loss: 0.4837 - accuracy: 0.8012 - val_loss: 0.4243 - val_accuracy: 0.8369\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 817s 8s/step - loss: 0.4823 - accuracy: 0.8036 - val_loss: 0.4165 - val_accuracy: 0.8452\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 668s 6s/step - loss: 0.4808 - accuracy: 0.8075 - val_loss: 0.3810 - val_accuracy: 0.8583\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 587s 6s/step - loss: 0.4594 - accuracy: 0.8084 - val_loss: 0.3675 - val_accuracy: 0.8619\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.3588 - accuracy: 0.8690\n",
      "Validation accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Base directory for the dataset\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Severities\"\n",
    "\n",
    "# Main folders with their subfolders\n",
    "main_folders = {\n",
    "    \"Cataract\": [\"Cataract_low\", \"Cataract_medium\", \"Cataract_high\"],\n",
    "    \"Diabetic Retinopathy\": [\"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\"],\n",
    "    \"Normal\": [],  # No subfolders for Normal\n",
    "    \"Glaucoma\": [\"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"],\n",
    "}\n",
    "\n",
    "# Prepare the data generator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,  # Example augmentation settings\n",
    "    horizontal_flip=True  # Example augmentation setting\n",
    ")\n",
    "\n",
    "# Training dataset from specified subfolders\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # DenseNet input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation dataset from specified subfolders\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # DenseNet input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load the pre-trained DenseNet121 model without the top layer (for transfer learning)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for our specific problem\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Flattening\n",
    "x = layers.Dense(256, activation='relu')(x)  # Fully connected layer\n",
    "x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
    "output = layers.Dense(train_generator.num_classes, activation='softmax')(x)  # Output layer for categorical classification\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base DenseNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Use pre-trained weights\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203a9247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Path to save the model\n",
    "save_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\"\n",
    "\n",
    "# Save the model\n",
    "model.save(save_path)\n",
    "print(\"Model saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38055a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model from a saved file\n",
    "model_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\model.h5\"\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# Define the class names based on the subfolder names used during training\n",
    "class_names = [\n",
    "    \"Cataract_low\", \"Cataract_medium\", \"Cataract_high\",\n",
    "    \"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\",\n",
    "    \"Normal\",\n",
    "    \"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"\n",
    "]\n",
    "\n",
    "# Load and preprocess an image for prediction\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Adjust target size to your model's input\n",
    "    img_array = image.img_to_array(img)  # Convert the image to an array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "    img_array /= 255.0  # Rescale to the same range used during training\n",
    "    return img_array\n",
    "\n",
    "# Function to make a prediction and return the predicted class\n",
    "def predict_class(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    prediction = model.predict(img_array)  # Get the prediction\n",
    "    predicted_class_index = np.argmax(prediction)  # Get the index of the highest probability\n",
    "    predicted_class_name = class_names[predicted_class_index]  # Map index to class name\n",
    "    return predicted_class_name\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\test_image.jpg\"\n",
    "predicted_class = predict_class(image_path)\n",
    "\n",
    "print(f\"The predicted class for the given image is: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313ce328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model from a saved file\n",
    "model_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\"\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# Define the class names based on the subfolder names used during training\n",
    "class_names = [\n",
    "    \"Cataract_low\", \"Cataract_medium\", \"Cataract_high\",\n",
    "    \"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\",\n",
    "    \"Normal\",\n",
    "    \"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"\n",
    "]\n",
    "\n",
    "# Load and preprocess an image for prediction\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Adjust target size to your model's input\n",
    "    img_array = image.img_to_array(img)  # Convert the image to an array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "    img_array /= 255.0  # Rescale to the same range used during training\n",
    "    return img_array\n",
    "\n",
    "# Function to make a prediction and return the predicted class\n",
    "# Function to make a prediction and return the predicted class along with prediction probabilities\n",
    "def predict_class(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    prediction = model.predict(img_array)  # Get the prediction\n",
    "    predicted_class_index = np.argmax(prediction)  # Get the index of the highest probability\n",
    "    predicted_class_name = class_names[predicted_class_index]  # Map index to class name\n",
    "    return predicted_class_name, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a5967e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 302ms/step\n",
      "The predicted class for the given image is: Cataract_low\n",
      "Prediction probabilities: [[8.22453260e-01 5.57376305e-04 1.06499255e-01 7.04900548e-02]]\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\\_19_9976222.jpg\"\n",
    "predicted_class, prediction_probabilities = predict_class(image_path)\n",
    "\n",
    "print(f\"The predicted class for the given image is: {predicted_class}\")\n",
    "print(f\"Prediction probabilities: {prediction_probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7620fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 308ms/step\n",
      "The predicted class for the given image is: Cataract_medium\n",
      "Prediction probabilities: [[0.01709453 0.7209907  0.02365575 0.23825894]]\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\\10266_right.jpeg\"\n",
    "predicted_class, prediction_probabilities = predict_class(image_path)\n",
    "\n",
    "print(f\"The predicted class for the given image is: {predicted_class}\")\n",
    "print(f\"Prediction probabilities: {prediction_probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99b9de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 325ms/step\n",
      "The predicted class for the given image is: Diabetic Retinopathy_low\n",
      "Prediction probabilities: [[0.00235401 0.43688455 0.0414187  0.5193428 ]]\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\\10149_left.jpeg\"\n",
    "predicted_class, prediction_probabilities = predict_class(image_path)\n",
    "\n",
    "print(f\"The predicted class for the given image is: {predicted_class}\")\n",
    "print(f\"Prediction probabilities: {prediction_probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f8eac59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 309ms/step\n",
      "The predicted class for the given image is: Cataract_high\n",
      "Prediction probabilities: [[0.14263579 0.0232724  0.55246204 0.28162974]]\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\\_33_7463078.jpg\"\n",
    "predicted_class, prediction_probabilities = predict_class(image_path)\n",
    "\n",
    "print(f\"The predicted class for the given image is: {predicted_class}\")\n",
    "print(f\"Prediction probabilities: {prediction_probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6a8e3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 4 classes.\n",
      "4/4 [==============================] - 27s 5s/step - loss: 0.4853 - accuracy: 0.8167\n",
      "Test accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Base directory for the test dataset\n",
    "test_base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\"\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\"\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# Prepare the data generator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test dataset from specified subfolders\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_base_dir,\n",
    "    target_size=(224, 224),  # Ensure it matches the model's input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadc40a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91790\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdbd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 4 classes.\n",
      "4/4 [==============================] - 25s 5s/step\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Cataract       0.81      0.83      0.82        30\n",
      "Diabetic Retinopathy       0.80      0.93      0.86        30\n",
      "            Glaucoma       0.85      0.77      0.81        30\n",
      "              Normal       0.81      0.73      0.77        30\n",
      "\n",
      "            accuracy                           0.82       120\n",
      "           macro avg       0.82      0.82      0.82       120\n",
      "        weighted avg       0.82      0.82      0.82       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report  # For precision, recall, F1, and accuracy\n",
    "\n",
    "# Base directory for the test dataset\n",
    "test_base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Test Dataset\"\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\DenseNet\"\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# Prepare the data generator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test dataset from specified subfolders\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_base_dir,\n",
    "    target_size=(224, 224),  # Ensure it matches the model's input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Do not shuffle to maintain label order\n",
    ")\n",
    "\n",
    "# Get the true labels from the test generator\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get class names from the generator\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Calculate the classification report with precision, recall, F1, and accuracy\n",
    "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c821d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
