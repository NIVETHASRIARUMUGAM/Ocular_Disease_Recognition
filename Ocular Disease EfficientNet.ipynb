{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1746ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: Cataract/Cataract_low\n",
      "Extracted HOG features from 382 images in 'Cataract/Cataract_low'\n",
      "Processing subfolder: Cataract/Cataract_medium\n",
      "Extracted HOG features from 350 images in 'Cataract/Cataract_medium'\n",
      "Processing subfolder: Cataract/Cataract_high\n",
      "Extracted HOG features from 300 images in 'Cataract/Cataract_high'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_low\n",
      "Extracted HOG features from 317 images in 'Diabetic Retinopathy/Diabetic Retinopathy_low'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_medium\n",
      "Extracted HOG features from 401 images in 'Diabetic Retinopathy/Diabetic Retinopathy_medium'\n",
      "Processing subfolder: Diabetic Retinopathy/Diabetic Retinopathy_high\n",
      "Extracted HOG features from 380 images in 'Diabetic Retinopathy/Diabetic Retinopathy_high'\n",
      "Processing main folder: Normal\n",
      "Extracted HOG features from 1074 images in 'Normal'\n",
      "Processing subfolder: Glaucoma/Glaucoma_low\n",
      "Extracted HOG features from 354 images in 'Glaucoma/Glaucoma_low'\n",
      "Processing subfolder: Glaucoma/Glaucoma_medium\n",
      "Extracted HOG features from 298 images in 'Glaucoma/Glaucoma_medium'\n",
      "Processing subfolder: Glaucoma/Glaucoma_high\n",
      "Extracted HOG features from 355 images in 'Glaucoma/Glaucoma_high'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Base directory where the main folders are located\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Severities\"\n",
    "\n",
    "# Main folders with their subfolders\n",
    "main_folders = {\n",
    "    \"Cataract\": [\"Cataract_low\", \"Cataract_medium\", \"Cataract_high\"],\n",
    "    \"Diabetic Retinopathy\": [\"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\"],\n",
    "    \"Normal\": [],  # No subfolders for Normal\n",
    "    \"Glaucoma\": [\"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"],\n",
    "}\n",
    "\n",
    "# Dictionary to store features for all subfolders\n",
    "features_by_folder = {}\n",
    "\n",
    "# Function to extract HOG features from a grayscale image\n",
    "def extract_hog_features(image):\n",
    "    # Extract HOG features and a visualization image\n",
    "    hog_features, hog_image = hog(image, visualize=True, pixels_per_cell=(16, 16), cells_per_block=(1, 1), feature_vector=True)\n",
    "    \n",
    "    # Rescale the HOG image for visualization (optional)\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    \n",
    "    return hog_features, hog_image_rescaled\n",
    "\n",
    "# Function to read images from a folder and extract HOG features\n",
    "def read_and_extract_features(folder_path):\n",
    "    # List all image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Store HOG features from this folder\n",
    "    hog_features_list = []\n",
    "\n",
    "    # Loop through each image and extract HOG features\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is not None:\n",
    "            # Extract HOG features\n",
    "            hog_features, _ = extract_hog_features(image)\n",
    "\n",
    "            # Append the HOG features to the list\n",
    "            hog_features_list.append(hog_features)\n",
    "    \n",
    "    return hog_features_list\n",
    "\n",
    "# Loop through each main folder and its subfolders to extract HOG features\n",
    "for main_folder, subfolder_list in main_folders.items():\n",
    "    if subfolder_list:\n",
    "        # Process each subfolder under the main folder\n",
    "        for subfolder in subfolder_list:\n",
    "            print(f\"Processing subfolder: {main_folder}/{subfolder}\")\n",
    "            folder_path = os.path.join(base_dir, main_folder, subfolder)\n",
    "\n",
    "            # Extract features from the current subfolder\n",
    "            features = read_and_extract_features(folder_path)\n",
    "\n",
    "            # Store the extracted features in the dictionary\n",
    "            features_by_folder[f\"{main_folder}/{subfolder}\"] = features\n",
    "\n",
    "            # Provide feedback on the number of images processed\n",
    "            print(f\"Extracted HOG features from {len(features)} images in '{main_folder}/{subfolder}'\")\n",
    "    else:\n",
    "        # If no subfolders, process the main folder directly (like Normal)\n",
    "        print(f\"Processing main folder: {main_folder}\")\n",
    "        folder_path = os.path.join(base_dir, main_folder)\n",
    "\n",
    "        # Extract features from the current main folder\n",
    "        features = read_and_extract_features(folder_path)\n",
    "\n",
    "        # Store the extracted features in the dictionary\n",
    "        features_by_folder[main_folder] = features\n",
    "\n",
    "        # Provide feedback on the number of images processed\n",
    "        print(f\"Extracted HOG features from {len(features)} images in '{main_folder}'\")\n",
    "\n",
    "# Now 'features_by_folder' contains HOG features from all specified folders and subfolders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32be51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3371 images belonging to 4 classes.\n",
      "Found 840 images belonging to 4 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 9s 1us/step\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1294s 12s/step - loss: 1.4194 - accuracy: 0.2477 - val_loss: 1.3859 - val_accuracy: 0.2607\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1274s 12s/step - loss: 1.3865 - accuracy: 0.2480 - val_loss: 1.3860 - val_accuracy: 0.2548\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1279s 12s/step - loss: 1.3861 - accuracy: 0.2530 - val_loss: 1.3859 - val_accuracy: 0.2607\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1309s 12s/step - loss: 1.3859 - accuracy: 0.2608 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1279s 12s/step - loss: 1.3863 - accuracy: 0.2608 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1330s 12s/step - loss: 1.3859 - accuracy: 0.2548 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 962s 9s/step - loss: 1.3859 - accuracy: 0.2605 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1015s 10s/step - loss: 1.3859 - accuracy: 0.2608 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1398s 13s/step - loss: 1.3859 - accuracy: 0.2608 - val_loss: 1.3858 - val_accuracy: 0.2607\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1369s 13s/step - loss: 1.3858 - accuracy: 0.2608 - val_loss: 1.3857 - val_accuracy: 0.2607\n",
      "27/27 [==============================] - 268s 10s/step - loss: 1.3857 - accuracy: 0.2607\n",
      "Validation accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Base directory for the dataset\n",
    "base_dir = r\"C:\\Users\\91790\\OneDrive\\Desktop\\BHAVATHARINI\\OCULAR DISEASE\\Severities\"\n",
    "\n",
    "# Main folders with their subfolders\n",
    "main_folders = {\n",
    "    \"Cataract\": [\"Cataract_low\", \"Cataract_medium\", \"Cataract_high\"],\n",
    "    \"Diabetic Retinopathy\": [\"Diabetic Retinopathy_low\", \"Diabetic Retinopathy_medium\", \"Diabetic Retinopathy_high\"],\n",
    "    \"Normal\": [],  # No subfolders for Normal\n",
    "    \"Glaucoma\": [\"Glaucoma_low\", \"Glaucoma_medium\", \"Glaucoma_high\"],\n",
    "}\n",
    "\n",
    "# Prepare the data generator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,  # Example augmentation settings\n",
    "    horizontal_flip=True  # Example augmentation setting\n",
    ")\n",
    "\n",
    "# Training dataset from specified subfolders\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # EfficientNetB0 input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation dataset from specified subfolders\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # EfficientNetB0 input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load the pre-trained EfficientNetB0 model without the top layer (for transfer learning)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for our specific problem\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Flattening\n",
    "x = layers.Dense(256, activation='relu')(x)  # Fully connected layer\n",
    "x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
    "output = layers.Dense(train_generator.num_classes, activation='softmax')(x)  # Output layer for categorical classification\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base EfficientNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Use pre-trained weights\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38d8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063fb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
